name: CI Build → Push → Deploy (+ optional Sonar/Monitoring/Velero)

on:
  push:
    branches: [ "main" ]
  workflow_dispatch:

env:
  IMAGE_NAME: ${{ secrets.DOCKERHUB_USERNAME }}/nginx-demo
  IMAGE_TAG: latest
  K8S_NS: demo
  SONAR_MODE: ${{ vars.SONAR_MODE }}           # SELF_HOSTED / IN_JOB / (ว่าง = ข้าม)
  SONAR_HOST_PORT: ${{ vars.SONAR_HOST_PORT }} # ปกติ 9000

jobs:
  build_and_push:
    runs-on: ubuntu-latest
    env:
      SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}
    steps:
      - uses: actions/checkout@v4

      - name: Docker login
        run: echo "${{ secrets.DOCKERHUB_TOKEN }}" | docker login -u "${{ secrets.DOCKERHUB_USERNAME }}" --password-stdin

      - name: Build image
        run: docker build -t $IMAGE_NAME:$IMAGE_TAG -f web/Dockerfile web

      # --- Sonar (IN_JOB) ---
      - name: SonarQube Scan (IN_JOB service)
        if: ${{ env.SONAR_MODE == 'IN_JOB' && env.SONAR_TOKEN != '' }}
        run: |
          set -e
          docker network create sqnet || true
          docker run -d --name sq --network sqnet -p 9000:9000 sonarqube:10-community
          for i in {1..120}; do
            curl -sf http://localhost:9000/api/system/status | grep -q '"status":"UP"' && break || sleep 1
          done
          docker run --rm --network sqnet \
            -e SONAR_HOST_URL=http://sq:9000 \
            -e SONAR_LOGIN="$SONAR_TOKEN" \
            -v "$PWD:/usr/src" \
            sonarsource/sonar-scanner-cli:latest
          docker rm -f sq || true
          docker network rm sqnet || true

      # --- Sonar (SELF_HOSTED) ---
      - name: SonarQube Scan (SELF_HOSTED runner)
        if: ${{ env.SONAR_MODE == 'SELF_HOSTED' && env.SONAR_TOKEN != '' }}
        run: |
          set -e
          PORT="${SONAR_HOST_PORT:-9000}"
          docker run --rm \
            -e SONAR_HOST_URL="http://host.docker.internal:${PORT}" \
            -e SONAR_LOGIN="$SONAR_TOKEN" \
            -v "$PWD:/usr/src" \
            sonarsource/sonar-scanner-cli:latest

      - name: Push image
        run: docker push $IMAGE_NAME:$IMAGE_TAG

  deploy_minikube:
    needs: build_and_push
    runs-on: self-hosted
    steps:
      - uses: actions/checkout@v4
      - name: Apply / Update K8s
        run: |
          kubectl apply -f k8s/namespace.yaml
          kubectl -n $K8S_NS apply -f k8s/service.yaml
          kubectl -n $K8S_NS set image deploy/nginx-demo nginx=$IMAGE_NAME:$IMAGE_TAG
          kubectl -n $K8S_NS rollout status deploy/nginx-demo --timeout=180s
          kubectl -n $K8S_NS get po,svc

  monitoring_stack:
    needs: deploy_minikube
    runs-on: self-hosted
    steps:
      - name: Ensure prometheus repo
        run: |
          helm repo add prometheus-community https://prometheus-community.github.io/helm-charts || true
          helm repo update
      - name: Install/Upgrade kube-prometheus-stack
        run: |
          kubectl create ns monitoring --dry-run=client -o yaml | kubectl apply -f -
          helm upgrade --install kps prometheus-community/kube-prometheus-stack -n monitoring \
            --set grafana.service.type=NodePort \
            --set prometheus.service.type=NodePort
          kubectl -n monitoring get pods
      - name: Print URLs
        run: |
          G=$(kubectl -n monitoring get svc kps-grafana -o jsonpath='{.spec.ports[0].nodePort}')
          P=$(kubectl -n monitoring get svc kps-kube-prometheus-stack-prometheus -o jsonpath='{.spec.ports[0].nodePort}')
          echo "Grafana:     http://$(minikube ip):${G}"
          echo "Prometheus:  http://$(minikube ip):${P}"

  velero_backup:
    needs: deploy_minikube
    runs-on: self-hosted
    env:
      VELERO_CREDS: ${{ secrets.VELERO_CREDS }} # optional; ถ้าไม่มีจะใช้ค่า minioadmin/minioadmin123 ชั่วคราว
    steps:
      - name: Install/Verify Velero against MinIO
        shell: bash
        run: |
          set -euxo pipefail

          # 1) Namespace
          kubectl create ns velero --dry-run=client -o yaml | kubectl apply -f - || true

          # 2) Ensure velero CLI exists
          if ! command -v velero >/dev/null 2>&1; then
            echo "Please install velero CLI on self-hosted runner"; exit 1
          fi

          # 3) Write credentials (no heredoc)
          if [[ -n "${VELERO_CREDS:-}" ]]; then
            printf "%s\n" "${VELERO_CREDS}" > credentials-velero
          else
            {
              printf "[default]\n"
              printf "aws_access_key_id=%s\n" "minioadmin"
              printf "aws_secret_access_key=%s\n" "minioadmin123"
            } > credentials-velero
          fi

          # 4) Install/upgrade Velero pointing to MinIO service inside cluster
          velero install \
            --provider aws \
            --plugins velero/velero-plugin-for-aws:v1.8.2 \
            --bucket velero \
            --secret-file ./credentials-velero \
            --backup-location-config region=minio,s3ForcePathStyle=true,s3Url=http://minio.minio.svc.cluster.local:9000 \
            --use-node-agent \
            --default-volumes-to-fs-backup \
            --namespace velero || true

          kubectl -n velero get pods

      - name: Run backup of demo namespace
        shell: bash
        run: |
          set -euxo pipefail
          velero backup create "demo-$(date +%Y%m%d-%H%M)" --include-namespaces $K8S_NS
          velero backup get
