name: CI Build → Push → Deploy (+ optional Sonar/Monitoring/Velero)

on:
  push:
    branches: [ "main" ]
  workflow_dispatch:

env:
  IMAGE_NAME: ${{ secrets.DOCKERHUB_USERNAME }}/nginx-demo
  IMAGE_TAG: latest
  K8S_NS: demo
  # อ่านค่าโหมด/พอร์ตของ Sonar จาก repo variables (ตั้งใน Settings → Secrets and variables → Actions → Variables)
  SONAR_MODE: ${{ vars.SONAR_MODE }}          # 'SELF_HOSTED' หรือ 'IN_JOB' หรือปล่อยว่างเพื่อปิด
  SONAR_HOST_PORT: ${{ vars.SONAR_HOST_PORT }} # ปกติ 9000 (ถ้าคุณเปิด 9001 ก็ใส่ 9001)

jobs:
  build_and_push:
    runs-on: ubuntu-latest
    env:
      # expose token ให้ step อ่านผ่าน env (ห้ามอ้าง secrets ใน if โดยตรง)
      SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}
    steps:
      - uses: actions/checkout@v4

      - name: Docker login
        run: echo "${{ secrets.DOCKERHUB_TOKEN }}" | docker login -u "${{ secrets.DOCKERHUB_USERNAME }}" --password-stdin

      - name: Build image
        run: docker build -t $IMAGE_NAME:$IMAGE_TAG -f web/Dockerfile web

      # ---------- SONAR: โหมด IN_JOB (รัน SonarQube เป็น service ชั่วคราวใน job นี้) ----------
      - name: SonarQube Scan (IN_JOB service)
        if: ${{ env.SONAR_MODE == 'IN_JOB' && env.SONAR_TOKEN != '' }}
        run: |
          set -e
          docker network create sqnet || true
          docker run -d --name sq --network sqnet -p 9000:9000 sonarqube:10-community
          # รอจน ready (สูงสุด ~120s)
          for i in {1..120}; do
            if curl -sf http://localhost:9000/api/system/status | grep -q '"status":"UP"'; then
              break
            fi
            sleep 1
          done
          docker run --rm --network sqnet \
            -e SONAR_HOST_URL=http://sq:9000 \
            -e SONAR_LOGIN="$SONAR_TOKEN" \
            -v "$PWD:/usr/src" \
            sonarsource/sonar-scanner-cli:latest
          docker rm -f sq || true
          docker network rm sqnet || true

      # ---------- SONAR: โหมด SELF_HOSTED (runner บน Mac เข้าถึง Sonar ในเครื่องผ่าน host.docker.internal) ----------
      - name: SonarQube Scan (SELF_HOSTED runner)
        if: ${{ env.SONAR_MODE == 'SELF_HOSTED' && env.SONAR_TOKEN != '' }}
        run: |
          set -e
          PORT="${SONAR_HOST_PORT:-9000}"
          docker run --rm \
            -e SONAR_HOST_URL="http://host.docker.internal:${PORT}" \
            -e SONAR_LOGIN="$SONAR_TOKEN" \
            -v "$PWD:/usr/src" \
            sonarsource/sonar-scanner-cli:latest

      - name: Push image
        run: docker push $IMAGE_NAME:$IMAGE_TAG

  deploy_minikube:
    needs: build_and_push
    runs-on: self-hosted    # runner บน Mac ของคุณ
    steps:
      - uses: actions/checkout@v4
      - name: Apply / Update K8s
        run: |
          kubectl apply -f k8s/namespace.yaml
          kubectl -n $K8S_NS apply -f k8s/service.yaml
          kubectl -n $K8S_NS set image deploy/nginx-demo nginx=$IMAGE_NAME:$IMAGE_TAG
          kubectl -n $K8S_NS rollout status deploy/nginx-demo --timeout=180s
          kubectl -n $K8S_NS get po,svc

  monitoring_stack:
    needs: deploy_minikube
    runs-on: self-hosted
    steps:
      - name: Ensure prometheus-community repo
        run: |
          helm repo add prometheus-community https://prometheus-community.github.io/helm-charts || true
          helm repo update
      - name: Install/Upgrade kube-prometheus-stack (Prometheus+Grafana)
        run: |
          kubectl create ns monitoring --dry-run=client -o yaml | kubectl apply -f -
          helm upgrade --install kps prometheus-community/kube-prometheus-stack -n monitoring \
            --set grafana.service.type=NodePort \
            --set grafana.service.nodePort=31300 \
            --set prometheus.service.type=NodePort \
            --set prometheus.service.nodePort=31301
          kubectl -n monitoring get pods
      - name: Grafana/Prometheus URLs
        run: |
          echo "Grafana:   http://$(minikube ip):31300"
          echo "Prometheus: http://$(minikube ip):31301"

  velero_backup:
    needs: deploy_minikube
    runs-on: self-hosted
    env:
      VELERO_CREDS: ${{ secrets.VELERO_CREDS }} # optional; ถ้าไม่มีจะสร้างไฟล์ชั่วคราวให้
    steps:
      - name: Install/Verify Velero against MinIO
        run: |
          set -e
          kubectl create ns velero --dry-run=client -o yaml | kubectl apply -f - || true
          if ! velero version >/dev/null 2>&1; then
            echo "Please install velero CLI on self-hosted runner"; exit 1
          fi
          if [ -z "$VELERO_CREDS" ]; then
            cat > credentials-velero <<'EOF'
            [default]
            aws_access_key_id=minioadmin
            aws_secret_access_key=minioadmin123
            EOF
          else
            echo "$VELERO_CREDS" > credentials-velero
          fi
          velero install \
            --provider aws \
            --plugins velero/velero-plugin-for-aws:v1.8.2 \
            --bucket velero \
            --secret-file ./credentials-velero \
            --backup-location-config region=minio,s3ForcePathStyle=true,s3Url=http://minio.minio.svc.cluster.local:9000 \
            --use-node-agent \
            --default-volumes-to-fs-backup \
            --namespace velero || true
          kubectl -n velero get pods
      - name: Run backup of demo namespace
        run: |
          velero backup create demo-$(date +%Y%m%d-%H%M) --include-namespaces $K8S_NS
          velero backup get
